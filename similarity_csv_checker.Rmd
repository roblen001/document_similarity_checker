---
title: "similarity_csv_checker"
author: "Roberto Lentini"
date: "27/05/2021"
output: html_document
---
```{r}
# imports
library(tidyverse)
library(tidytext)
library(tidyverse)
library(pluralize)
library(naniar)
library(data.table)
library(purrr)
```

```{r}
data <- read.csv('C:/document_similarity_checker/ONDRISubmissionPortalFullList .csv')
colnames(data)
colnames(data) <- c('id','author', 'title', 'text')
corpus_raw <- data %>% select('id', 'author', 'title', 'text')
head(corpus_raw)
```

```{r}
data(stop_words)
custom_bigram_stop_words <- c('university press', 'citing article', 'https www.tandfonline.com')
custom_stop_words <- c('copyright', 'https', 'NA')
corpus_clean <- corpus_raw %>%
  unnest_tokens(output = word, input = text, token = "ngrams", n = 3)%>%
  separate(word, c("word1", "word2", "word3"), sep = " ")
  
print(corpus_clean)

corpus_clean1 <- corpus_clean %>%
  filter(!word1 %in% c(stop_words$word, custom_stop_words)) %>%
  filter(!word2 %in% c(stop_words$word, custom_stop_words)) %>% 
  filter(!word3 %in% c(stop_words$word, custom_stop_words)) %>%
  unite(word, word1, word2, word3, sep = " ") %>%
  filter(!word %in% custom_bigram_stop_words)

print(corpus_clean1)
```
visualize
```{r}

corpus_clean1$word <- singularize(corpus_clean1$word)

corpus_clean1 <- corpus_clean1 %>%
  group_by(title) %>%
  count(word, sort = TRUE) 
```

flipping word and n
```{r}
corpus_clean <- corpus_clean1 %>%
  pivot_wider(names_from = word, values_from = n)
corpus_clean
# set keyword amount to NA if it is below a certain threshold
colnames(corpus_clean)
print('visualize ==============================')

# remove cols with less then 2 NAs
visualize <- corpus_clean[, which(colMeans(!is.na(corpus_clean)) > 1/length(corpus_clean$title))]
visualize
```
creating an index to quantify similarity
```{r}
#  giving the amount of keywords a weight
visualize_matrix <- subset(visualize, select = -c(title) )
visualize_matrix[is.na((visualize_matrix))] <- 0
# visualize_matrix[visualize_matrix != 0] <- 1

visualize_matrix[1 < visualize_matrix & visualize_matrix <= 5] <- 1
visualize_matrix[5 < visualize_matrix & visualize_matrix <= 10] <- 2
visualize_matrix[10 < visualize_matrix & visualize_matrix <= 20] <- 3
visualize_matrix[20 < visualize_matrix & visualize_matrix] <- 4


# visualize_matrix[30 < visualize_matrix & visualize_matrix < 40] <- 4 
# visualize_matrix[40 < visualize_matrix & visualize_matrix < 50] <- 5 
# visualize_matrix[50 < visualize_matrix ] <- 6 

visualize_matrix <- as.matrix(visualize_matrix)
contengency_table_matrix <- visualize_matrix %*%  t(visualize_matrix)
# set diagonal to -1
diag(contengency_table_matrix) <- -1
# list of max values
max_values <- apply(contengency_table_matrix,1,max)

# get list of max values ie. most similar 
# contengency_table_matrix[is.na((contengency_table_matrix))] <- -1
# print(apply(contengency_table_matrix,1, max))
diag(contengency_table_matrix) <- NA
# for visual
contengency_table <- as.tibble(contengency_table_matrix)
contengency_table  <- setnames(contengency_table, old = colnames(contengency_table), corpus_clean$title)

# list of most related articles
most_related_articles <- colnames(contengency_table)[apply(contengency_table,1,which.max)]
similar_articles <- tibble(corpus_clean$title, most_related_articles, max_values)

colnames(similar_articles) <- c("title", "most_similar_proposal", "common_words_weighted")
   
print(similar_articles)

contengency_table <- contengency_table %>%
  add_column(corpus_clean$title)
```


```{r}
visualize_long <- visualize %>% 
  pivot_longer(!title, names_to = "keywords", values_to = "count") %>%
  drop_na() %>%
  select(title, keywords)

visualize_long <- visualize_long %>% group_by(title) %>%
  summarise(
     alltypes = paste(keywords, collapse=", "))

results <- merge(similar_articles, visualize_long, by='title' )
results <- merge(results, visualize_long, by.x = "most_similar_proposal", by.y = "title" )
results
s <- strsplit(results$alltypes.x , split = ", ")
a <- strsplit(results$alltypes.y , split = ", ")

common_words_list = vector('list', length(s))
for (i in 1:length(s)) {
  common_words <- pmap(list(s[i], a[i]), intersect)
  common_words_list[[i]] <- common_words
}

results <- results %>%
  add_column(common_words_list)
  
results <- results %>% 
  select(title, most_similar_proposal, common_words_weighted, common_words_list)

# similar_articles %>% arrange(article) %>% add_column(test = visualize_long$alltypes) %>% arrange(most_related_articles) %>% add_column(test2 = visualize_long$alltypes)


# common_words <- pmap(list(similar_articles_ordered_by_articles$common_words, similar_articles_ordered_by_most_similar_articles$common_words), intersect)
# print(common_words)

# write.csv(results, 'results.csv')
# 
# 
# pmap(list(w1, w2), intersect)


```

